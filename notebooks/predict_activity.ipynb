{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict activity\n",
    "## A notebook for predicting the activity of a set of compounds\n",
    "The top 3 models (KNN, Random Forest and XGBoost) are used here for classifying a new set of compounds, and show to be relatively good classifiers. The confusion matrices show that KNeighborsClassifier had the highest true postive rate and the highest AUC, which are both important factors in drug discovery. However, none of the three classifiers correlated with the experimental activity values (fluorescence) according to the Spearman correlation values, indicating they had low early recognition (the classifiers couldn't rank the compounds according to their likelihood of being more active than others). \n",
    "## Instructions\n",
    "1. Define the name of the file that contains the compounds. Each molecule must...\n",
    "    1. ...be identified by \"CID\";\n",
    "    2. ...have an activity label (either active or inactive);\n",
    "    3. ...have values for the molecular descriptors defined in [Classifiers and molecular descriptors](#classifiers).\n",
    "    \n",
    "## How it works\n",
    "The models have already been trained and serialized (saved) to a pickle file. They are loaded and receive as input the activity data and values of molecular descriptors for a set of compounds. Finally, the models predict the activity of these compounds based on the data they have been previously trained on. \n",
    "\n",
    "## Table of contents\n",
    "1. [Read data](#read)\n",
    "2. [Classifiers and molecular descriptors](#classifiers)\n",
    "3. [Confusion matrices](#confusion)\n",
    "4. [ROC curves](#roc)    \n",
    "5. [Class distribution](#class)    \n",
    "6. [Spearman correlations](#spearman)    \n",
    "7. [Error metrics](#error)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read'></a>\n",
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing the compounds and their molecular descriptors\n",
    "# Define the name of the input file here\n",
    "compounds = None\n",
    "# Define the name of the activity label here\n",
    "activity_label = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv(compounds)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classifiers'></a>\n",
    "## Classifiers and molecular descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_dict = {}\n",
    "# Top 3 models\n",
    "descriptors_dict['RandomForestClassifier'] = ['NumRotatableBonds', 'NumHDonors', 'TPSA', 'LabuteASA']\n",
    "descriptors_dict['KNeighborsClassifier'] = ['NumHAcceptors', 'TPSA', 'LabuteASA']\n",
    "descriptors_dict['XGBClassifier'] = ['NumRotatableBonds', 'TPSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(model_name):\n",
    "    import pickle\n",
    "    file = open(f'../pickle/{model_name}.pickle', 'rb')\n",
    "    model_fitted = pickle.load(file)\n",
    "    file.close()\n",
    "    return model_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='confusion'></a>\n",
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_test, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "    matrix = pd.DataFrame(conf_matrix)\n",
    "    print(matrix.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = test_data[activity_label]\n",
    "Y = pd.DataFrame(test_data['CID'])\n",
    "probas = pd.DataFrame(test_data['CID'])\n",
    "\n",
    "for model_name in descriptors_dict.keys():\n",
    "    model_fitted = load_pickle(model_name)\n",
    "    subset = descriptors_dict[model_name]\n",
    "    X_test = test_data[subset]\n",
    "    y_pred = model_fitted.predict(X_test)\n",
    "    Y[model_name] = y_pred\n",
    "    \n",
    "    print('\\n', model_name)\n",
    "    print_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    y_proba = model_fitted.predict_proba(X_test)\n",
    "    probas[model_name] = y_proba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='roc'></a>\n",
    "## ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "for model_name in descriptors_dict.keys():\n",
    "    y_proba = probas[model_name]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name}: {auc(fpr, tpr):>.3f}')\n",
    "    \n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.legend(title='Area Under the Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='class'></a>\n",
    "## Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_dist(values):\n",
    "    values = pd.Series(values, name='values')\n",
    "    distribution = values.value_counts(\n",
    "        normalize=True).mul(100).reset_index().rename({'values':'Percentage','index':'Class'}, axis=1)\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perc = percentage_dist(test_data[activity_label])\n",
    "perc['Name'] = 'Experimental data'\n",
    "\n",
    "for model_name in descriptors_dict.keys():\n",
    "    y_pred = Y[model_name]\n",
    "    dist = percentage_dist(y_pred)\n",
    "    dist['Name'] = model_name\n",
    "    perc = perc.append(dist)\n",
    "\n",
    "sns.catplot(kind='bar', data=perc, x='Class', y='Percentage', hue='Name')\n",
    "plt.title('Number of active/inactive compounds according to the experimental data and number of classified active/inactive compounds', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spearman'></a>\n",
    "## Spearman correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "df = pd.merge(activity[['CID', 'f_inhibition_at_50_uM']], probas, on=['CID'])\n",
    "print('Spearman R')\n",
    "for model_name in descriptors_dict.keys():\n",
    "    print(f'{model_name}: {spearmanr(df[model_name], df[\"f_inhibition_at_50_uM\"])[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='error'></a>\n",
    "## Error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metrics(y_test, y_proba):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import log_loss\n",
    "    \n",
    "    rmse = np.linalg.norm(y_proba - y_test) / np.sqrt(len(y_test))\n",
    "    logl = log_loss(y_test, y_proba)\n",
    "    return rmse, logl\n",
    "    print('{:.4f}'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:20s}\\t{:5s}\\t{:5s}'.format('Model', 'RMSE', 'log_loss'))\n",
    "for model_name in descriptors_dict.keys():\n",
    "    rmse, logl = error_metrics(y_test, probas[model_name])\n",
    "    print(f'{model_name:20s}\\t{rmse:.4f}\\t{logl:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
